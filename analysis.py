# -*- coding: utf-8 -*-
"""Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gt5jMLRWzkBnPntnzLU4MBPGzSZazo8W
"""

!pip install -q pandas numpy matplotlib seaborn wordcloud vaderSentiment scikit-learn snowflake-connector-python

import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
import seaborn as sns
import snowflake.connector
from matplotlib import cm
from matplotlib.ticker import ScalarFormatter, FuncFormatter
from wordcloud import WordCloud, STOPWORDS
from collections import Counter
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Establish connection to Snowflake
conn = snowflake.connector.connect(
    user="USER1204",
    password="Review20251018@",
    account="XUZXIIE-EAC06737",
    warehouse="COMPUTE_WH",
    database="GPT_REVIEWS_DB",
    schema="PUBLIC",
    role="ACCOUNTADMIN"
)

# Query the reviews table
query = "SELECT * FROM reviews"
df = pd.read_sql(query, conn)
print(f"Loaded {len(df):,} rows with {len(df.columns)} columns from Snowflake.")

# Query app metadata table
# metadata_df = pd.read_sql("SELECT * FROM app_metadata", conn)
# print(f"Loaded {len(metadata_df):,} rows from app_metadata.")

# Close the Snowflake connection
conn.close()

"""1. Basic Data Overview"""

# Preview basic information about the dataset
print("\nPreview of the first 5 rows:")
print(df.head(5).to_string(index=False))

# Check for missing values
print("\nMissing value count by column:")
print(df.isna().sum())

# Print data type info
print("\nColumn data types:")
print(df.dtypes)

"""2. Data Quality & Bias Check

Missing value visualization
"""

plt.figure(figsize=(8, 4))
(df.isna().mean() * 100).sort_values(ascending=False).plot(kind='bar', edgecolor='black')
plt.title("Percentage of Missing Values by Column")
plt.ylabel("Percentage (%)")
plt.xlabel("Column")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""Check Duplicate reviewId"""

# Check for duplicate review IDs
dup_count = df["REVIEW_ID"].duplicated().sum()
print(f"Duplicate REVIEW_ID count: {dup_count}")

"""Count Active Users"""

if "userName" in df.columns:
    user_counts = df["userName"].value_counts()
    active_users = user_counts[user_counts > 1]
    print(f"Total unique users: {df['userName'].nunique()}")
    print(f"Users with >1 review: {len(active_users)} ({len(active_users)/df['userName'].nunique():.1%})")

    # Mark active users
    df["is_active_user"] = df["userName"].isin(active_users.index)

"""3. Rating Analysis

Rating Distribution
"""

plt.figure(figsize=(7, 4))

counts = df["SCORE"].value_counts(dropna=False).sort_index()

plt.bar(
    counts.index.astype(str),
    counts.values,
    edgecolor="black",
    linewidth=1.0
)

plt.title("Score Distribution (1–5)", fontsize=13)
plt.xlabel("Score")
plt.ylabel("Count")

plt.gca().yaxis.set_major_formatter(ScalarFormatter(useMathText=False))
plt.ticklabel_format(style='plain', axis='y')

plt.show()

"""4. Word Count Analysis

Review Length Distribution
"""

df["word_count"] = df["CONTENT"].astype(str).apply(lambda x: len(x.split()))

print("Text Length Stats")
print(df["word_count"].describe())

plt.figure(figsize=(7, 4))
plt.hist(df["word_count"].dropna(), bins=60, edgecolor="black", linewidth=1.0)

plt.title("Review Length Distribution", fontsize=13)
plt.xlabel("Words")
plt.ylabel("Count")

plt.gca().yaxis.set_major_formatter(ScalarFormatter())
plt.ticklabel_format(style="plain", axis="y")

plt.show()

"""Review Length by Rating"""

# Review Length by Rating
df["word_count"] = df["CONTENT"].apply(lambda x: len(x.split()))

avg_len_by_score = df.groupby("SCORE")["word_count"].agg(["mean", "median", "std"])

print("\n Average Review Length by Rating:")
print(avg_len_by_score)

plt.figure(figsize=(7, 4))
sns.barplot(
    x=avg_len_by_score.index,
    y=avg_len_by_score["mean"],
    edgecolor="black",
    linewidth=1.0
)

plt.title("Review Length by Rating", fontsize=13)
plt.xlabel("Score (1–5)")
plt.ylabel("Average Word Count")

plt.gca().yaxis.set_major_formatter(ScalarFormatter())
plt.ticklabel_format(style="plain", axis="y")

plt.tight_layout()
plt.show()

"""5. Sentiment Analysis

Sentiment Score
"""

# Initialize the sentiment analyzer
sid = SentimentIntensityAnalyzer()

# Apply sentiment analysis and extract compound score
df["SENTIMENT"] = df["CONTENT"].apply(lambda x: sid.polarity_scores(x)["compound"])

# Calculate correlation between sentiment and score
corr = df["SENTIMENT"].corr(df["SCORE"])
print(f"Pearson correlation (SENTIMENT vs SCORE): {corr:.4f}")

"""Sentiment Score & Rating over Time"""

# Convert CREATED_AT to datetime
df["CREATED_AT"] = pd.to_datetime(df["CREATED_AT"], errors="coerce")

# Extract year and month
df["YEAR_MONTH"] = df["CREATED_AT"].dt.to_period("M")

# Build full month range to ensure continuity
all_months = pd.period_range(df["YEAR_MONTH"].min(), df["YEAR_MONTH"].max(), freq="M")

# Group by month and compute mean score and mean sentiment
monthly = (
    df.groupby("YEAR_MONTH")
      .agg(MEAN_SCORE=("SCORE", "mean"),
           MEAN_SENT=("SENTIMENT", "mean"))
      .reindex(all_months)
      .reset_index()
      .rename(columns={"index": "YEAR_MONTH"})
)

# Convert month periods to string for plotting
xm = monthly["YEAR_MONTH"].astype(str)

# Create dual-axis line chart
fig, ax1 = plt.subplots(figsize=(12, 4.6))

# Average rating line
ax1.plot(xm, monthly["MEAN_SCORE"],
         marker="o", markersize=3, linewidth=1.8, alpha=0.9,
         label="Avg Rating", color="#1f77b4")
ax1.set_ylabel("Avg Rating", color="#1f77b4")

# Average sentiment line
ax2 = ax1.twinx()
ax2.plot(xm, monthly["MEAN_SENT"],
         marker="o", markersize=3, linewidth=1.8, alpha=0.9,
         label="Avg Sentiment", color="#2ca02c")
ax2.set_ylabel("Avg Sentiment", color="#2ca02c")

# Set x-axis ticks (1 tick per ~month)
step = max(1, len(xm) // 12)
ax1.set_xticks(range(0, len(xm), step), xm[::step], rotation=45, ha="right", fontsize=9)

# Grid and title
ax1.grid(axis="y", linestyle="--", alpha=0.45)
plt.title("Monthly Average Rating vs Sentiment")
plt.box(False)

# Merge legends from both axes
l1, lb1 = ax1.get_legend_handles_labels()
l2, lb2 = ax2.get_legend_handles_labels()
ax1.legend(l1 + l2, lb1 + lb2, loc="upper left", frameon=False)

plt.tight_layout()
plt.show()

"""Correlation Between Sentiment and Rating by Month"""

df["CREATED_AT"] = pd.to_datetime(df["CREATED_AT"], errors="coerce")

# Compute monthly correlation between SCORE and SENTIMENT
corr_by_month = (
    df.groupby(df["CREATED_AT"].dt.to_period("M"))[["SCORE", "SENTIMENT"]]
      .corr()
      .unstack()
      .iloc[:, 1]
)

# Plot correlation trend
plt.figure(figsize=(10, 4))
plt.plot(corr_by_month.index.astype(str), corr_by_month.values, marker="o", linewidth=1.8)

plt.title("Correlation Between Sentiment and Rating by Month")
plt.ylabel("Pearson r")
plt.xlabel("Month")
plt.xticks(rotation=45, ha="right")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

"""Sentiment Distribution by Rating"""

cand_cols = ["SENTIMENT", "SENTIMENT_VADER_CLEAN", "SENTIMENT_VADER_RAW"]
sent_col = next((c for c in cand_cols if c in df.columns), None)
assert sent_col is not None, "No sentiment column found. Expected one of: " + ", ".join(cand_cols)
assert "SCORE" in df.columns, "Missing column: SCORE"

# Prepare data
plot_df = df[[sent_col, "SCORE"]].dropna().copy()
plot_df["SCORE"] = plot_df["SCORE"].astype(int)

scores = [1, 2, 3, 4, 5]
data = [plot_df.loc[plot_df["SCORE"] == s, sent_col].values for s in scores]
counts = [len(d) for d in data]
means  = [np.mean(d) if len(d) else np.nan for d in data]

# Plot
plt.rcParams["figure.dpi"] = 160
fig, ax = plt.subplots(figsize=(8, 4.8))

# Boxplot
box = ax.boxplot(
    data,
    labels=[str(s) for s in scores],
    showfliers=False,
    patch_artist=True,
    widths=0.55
)

# Style
box_face = "#e8eef8"
box_edge = "#5b6d7a"
median_col = "#1f77b4"
whisker_col = "#94a3b8"
cap_col = "#94a3b8"

for patch in box["boxes"]:
    patch.set(facecolor=box_face, edgecolor=box_edge, linewidth=1.5)

for whisker in box["whiskers"]:
    whisker.set(color=whisker_col, linewidth=1.3)

for cap in box["caps"]:
    cap.set(color=cap_col, linewidth=1.3)

for median in box["medians"]:
    median.set(color=median_col, linewidth=2.0)

# Mean scatter
xpos = np.arange(1, len(scores) + 1)
ax.scatter(xpos, means, s=28, c="black", zorder=3, label="Mean")

# x-axis labels with counts
xtick_labels = [f"{s}\n(n={c:,})" for s, c in zip(scores, counts)]
ax.set_xticklabels(xtick_labels)

ax.set_title("Sentiment Distribution by Rating (Boxplot)", pad=12, fontsize=13)
ax.set_xlabel("User Rating (1–5)")
ax.set_ylabel("Sentiment")
ax.set_ylim(-1.05, 1.05)
ax.yaxis.grid(True, linestyle="--", linewidth=0.7, alpha=0.5)
ax.set_axisbelow(True)
ax.legend(loc="lower right", frameon=False)

plt.tight_layout()
plt.show()

"""WordCloud by Rating Level"""

# Define stopwords
custom_stopwords = set(STOPWORDS)
custom_stopwords.update([
    "app", "chatgpt", "chat", "gpt", "chat gpt", "ai", "bot",
    "nice", "good", "use", "really", "thing", "much", "best", "lot", "even",
    "its", "you", "that", "one", "and", "the", "this", "for", "very", "now",
    "please", "thank", "thanks", "application", "apps"
])

# Clean text
def clean_text(t):
    t = str(t).lower()
    t = re.sub(r"http\S+|www\S+", "", t)
    t = re.sub(r"[^a-z\s]", "", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

df["CLEAN_CONTENT"] = df["CONTENT"].apply(clean_text)

# Split by sentiment group
pos_text_raw = " ".join(df.loc[df["SCORE"] >= 4, "CLEAN_CONTENT"].dropna())
neg_text_raw = " ".join(df.loc[df["SCORE"] <= 2, "CLEAN_CONTENT"].dropna())

# Raw word frequencies
def get_raw_freq(text, min_len=3):
    words = [w for w in text.split() if len(w) >= min_len]
    return dict(Counter(words).most_common(200))

raw_pos_freq = get_raw_freq(pos_text_raw)
raw_neg_freq = get_raw_freq(neg_text_raw)

top_n = 20
pos_top_raw = list(raw_pos_freq.items())[:top_n]
neg_top_raw = list(raw_neg_freq.items())[:top_n]

print("Top Words BEFORE Stopword Removal".ljust(45))
print("Positive Reviews (Score ≥ 4)".ljust(45), "Negative Reviews (Score ≤ 2)")
print("-" * 90)
for i in range(top_n):
    left = f"{pos_top_raw[i][0]:<15} {pos_top_raw[i][1]:<6}" if i < len(pos_top_raw) else ""
    right = f"{neg_top_raw[i][0]:<15} {neg_top_raw[i][1]:<6}" if i < len(neg_top_raw) else ""
    print(f"{left:<30} | {right}")

# Filtered frequencies (AFTER removing stopwords)
def get_filtered_freq(text, stopwords, min_len=3):
    words = [w for w in text.split() if w not in stopwords and len(w) >= min_len]
    return dict(Counter(words).most_common(200))

freq_pos = get_filtered_freq(pos_text_raw, custom_stopwords)
freq_neg = get_filtered_freq(neg_text_raw, custom_stopwords)


print("\n Top Words AFTER Stopword Removal")
print("Positive Reviews (Score ≥ 4)".ljust(45), "Negative Reviews (Score ≤ 2)")
print("-" * 90)
pos_top = list(freq_pos.items())[:top_n]
neg_top = list(freq_neg.items())[:top_n]
for i in range(top_n):
    left = f"{pos_top[i][0]:<15} {pos_top[i][1]:<6}" if i < len(pos_top) else ""
    right = f"{neg_top[i][0]:<15} {neg_top[i][1]:<6}" if i < len(neg_top) else ""
    print(f"{left:<30} | {right}")

# Sentiment-based coloring
analyzer = SentimentIntensityAnalyzer()
word_sent = {w: analyzer.polarity_scores(w)["compound"] for w in set(freq_pos) | set(freq_neg)}


def color_by_sentiment(word, font_size, position, orientation, random_state=None, **kwargs):

    s = word_sent.get(word, 0.0)
    s = np.sign(s) * (abs(s) ** 0.7)

    cmap = cm.get_cmap("RdBu")
    rgba = cmap((s + 1) / 2)


    if abs(s) < 0.15:
        rgba = (0.6, 0.6, 0.65, 1.0)

    r, g, b, a = [int(x * 255) for x in rgba]
    return f"rgb({r},{g},{b})"

# Generate word clouds
wc_pos = WordCloud(width=900, height=600, background_color="white",
                   stopwords=custom_stopwords, max_words=150, max_font_size=180
                  ).generate_from_frequencies(freq_pos)

wc_neg = WordCloud(width=900, height=600, background_color="white",
                   stopwords=custom_stopwords, max_words=150, max_font_size=180
                  ).generate_from_frequencies(freq_neg)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

axes[0].imshow(wc_pos.recolor(color_func=color_by_sentiment, random_state=3), interpolation="bilinear")
axes[0].set_title("Positive Reviews (Score ≥ 4)\nColor = Sentiment (Blue=Positive, Red=Negative)",
                  fontsize=13, color="#1f77b4")
axes[0].axis("off")

axes[1].imshow(wc_neg.recolor(color_func=color_by_sentiment, random_state=3), interpolation="bilinear")
axes[1].set_title("Negative Reviews (Score ≤ 2)\nColor = Sentiment (Blue=Positive, Red=Negative)",
                  fontsize=13, color="#d62728")
axes[1].axis("off")

plt.tight_layout()
plt.show()

"""Sarcastic Reviews"""

#Sarcastic reviews
sarcastic = df[(df["SCORE"] == 1) & (df["SENTIMENT"] > 0.5)]

if len(sarcastic) > 0:
    print(f"Detected {len(sarcastic)} potentially sarcastic or misclassified comments.\n")
    print("First 5 examples (full text):\n")

    for i, row in sarcastic.head(5).iterrows():
        print(f"- {row['CONTENT']}")
        print(f"  (sent={row['SENTIMENT']:.2f}, score={row['SCORE']}, version={row.get('APP_VERSION', 'N/A')})\n")
else:
    print("No sarcastic or misclassified comments found.")

"""Sarcastic / Misclassified Reviews by Month"""

# Extract year and month
df["YEAR_MONTH"] = df["CREATED_AT"].dt.to_period("M")
sarcastic["YEAR_MONTH"] = sarcastic["CREATED_AT"].dt.to_period("M")

# Define full month range
all_months = pd.period_range(df["YEAR_MONTH"].min(), df["YEAR_MONTH"].max(), freq="M")

# Count sarcastic reviews per month
monthly_sarcasm = (
    sarcastic.groupby("YEAR_MONTH")["REVIEW_ID"]
    .count()
    .reindex(all_months, fill_value=0)
)

# Rolling average (3-month centered)
trend = monthly_sarcasm.rolling(window=3, center=True).mean()

# Plot
plt.figure(figsize=(12, 5))
plt.bar(
    monthly_sarcasm.index.astype(str),
    monthly_sarcasm.values,
    edgecolor="black",
    alpha=0.8,
    color="#1f77b4"
)

# X-axis setup
x_labels = monthly_sarcasm.index.astype(str)
step = max(1, len(x_labels) // 14)
plt.xticks(range(0, len(x_labels), step), x_labels[::step], rotation=45, ha="right", fontsize=9)

# Rolling trend line
plt.plot(range(len(trend)), trend.values, color="#d62728", linewidth=2, alpha=0.8)

# Labels and title
plt.title("Number of Sarcastic / Misclassified Reviews by Month", fontsize=14, pad=12)
plt.ylabel("Count of Sarcastic Reviews", fontsize=12)
plt.xlabel("Month", fontsize=12)
plt.grid(axis="y", linestyle="--", alpha=0.5)
plt.box(False)
plt.tight_layout()
plt.show()

"""Sarcastic / Misclassified Reviews by Version"""

if "reviewCreatedVersion" in sarcastic.columns:
    version_sarcasm = sarcastic.groupby("reviewCreatedVersion")["reviewId"].count()

    def version_key(v):
        parts = re.findall(r'\d+', str(v))
        return tuple(map(int, parts)) if parts else (0,)
    version_sarcasm = version_sarcasm.sort_index(key=lambda x: x.map(version_key))

    plt.figure(figsize=(14,5))
    bars = plt.bar(
        version_sarcasm.index.astype(str),
        version_sarcasm.values,
        edgecolor="black",
        alpha=0.8,
        linewidth=0.6
    )

    plt.title("Number of Sarcastic / Misclassified Reviews by App Version", fontsize=14, pad=15)
    plt.ylabel("Count of Sarcastic Reviews", fontsize=12)
    plt.xlabel("App Version (Chronological Order)", fontsize=12)

    xticks = version_sarcasm.index.astype(str)
    step = max(1, len(xticks)//20)
    plt.xticks(range(0, len(xticks), step), xticks[::step], rotation=45, ha="right", fontsize=9)

    plt.grid(axis="y", linestyle="--", alpha=0.5)
    plt.box(False)

    plt.tight_layout()
    plt.show()

    print("\nTop versions with the most sarcastic/misclassified reviews:")
    print(version_sarcasm.sort_values(ascending=False).head(10))

"""6. Time Trends

Monthly Review Volume & Average Rating
"""

# Check that APP_VERSION exists
if "APP_VERSION" in sarcastic.columns:
    # Count sarcastic reviews per version
    version_sarcasm = sarcastic.groupby("APP_VERSION")["REVIEW_ID"].count()

    # Sort versions numerically where possible
    def version_key(v):
        parts = re.findall(r'\d+', str(v))
        return tuple(map(int, parts)) if parts else (0,)
    version_sarcasm = version_sarcasm.sort_index(key=lambda x: x.map(version_key))

    # Plot
    plt.figure(figsize=(14, 5))
    bars = plt.bar(
        version_sarcasm.index.astype(str),
        version_sarcasm.values,
        edgecolor="black",
        alpha=0.8,
        linewidth=0.6,
        color="#1f77b4"
    )

    plt.title("Number of Sarcastic / Misclassified Reviews by App Version", fontsize=14, pad=15)
    plt.ylabel("Count of Sarcastic Reviews", fontsize=12)
    plt.xlabel("App Version (Chronological Order)", fontsize=12)

    # X-axis labels
    xticks = version_sarcasm.index.astype(str)
    step = max(1, len(xticks) // 20)
    plt.xticks(range(0, len(xticks), step), xticks[::step], rotation=45, ha="right", fontsize=9)

    plt.grid(axis="y", linestyle="--", alpha=0.5)
    plt.box(False)
    plt.tight_layout()
    plt.show()

    # Print top versions
    print("\nTop versions with the most sarcastic/misclassified reviews:")
    print(version_sarcasm.sort_values(ascending=False).head(10))
else:
    print("Column APP_VERSION not found in sarcastic DataFrame.")

"""Average Review Length Over Time"""

if "WORD_COUNT" not in df.columns:
    df["WORD_COUNT"] = df["CONTENT"].astype(str).apply(lambda x: len(x.split()))

# Extract year-month
df["YEAR_MONTH"] = df["CREATED_AT"].dt.to_period("M")

# Compute average word count per month
monthly_length = df.groupby("YEAR_MONTH")["WORD_COUNT"].mean()

# Plot
plt.figure(figsize=(10, 4))
plt.plot(monthly_length.index.astype(str), monthly_length.values, marker="o", linewidth=1.8)
plt.title("Average Comment Length Over Time", fontsize=13)
plt.xlabel("Month")
plt.ylabel("Average Word Count")
plt.xticks(rotation=45, ha="right")
plt.grid(alpha=0.3)
plt.tight_layout()
plt.show()

"""7. Version Trends

Average Rating and Review Volume by Version
"""

# Average Rating and Review Volume by App Version

version_df = (
    df.groupby("APP_VERSION")
      .agg(
          REVIEW_COUNT=("REVIEW_ID", "count"),
          AVG_SCORE=("SCORE", "mean")
      )
      .reset_index()
      .dropna(subset=["APP_VERSION"])
)

# Define version sorting key
import re
def version_key(v):
    parts = re.findall(r'\d+', str(v))
    return tuple(map(int, parts)) if parts else (0,)

# Sort versions chronologically
version_df = version_df.sort_values(
    "APP_VERSION", key=lambda s: s.map(version_key)
).reset_index(drop=True)

# Plot
fig, ax1 = plt.subplots(figsize=(12, 5))

# Bar chart: review count
ax1.bar(
    version_df["APP_VERSION"].astype(str),
    version_df["REVIEW_COUNT"],
    color="lightblue",
    alpha=0.8,
    label="Review Count",
    edgecolor="black",
    linewidth=0.8
)
ax1.set_ylabel("Review Count", fontsize=11)
ax1.set_xlabel("App Version", fontsize=11)
ax1.tick_params(axis="y", labelcolor="black")

# Configure x-axis ticks
xticks = version_df["APP_VERSION"].astype(str).values
step = max(1, len(xticks) // 12)
ax1.set_xticks(range(0, len(xticks), step))
ax1.set_xticklabels(xticks[::step], rotation=45, ha="right", fontsize=9)

# Line plot: average score
ax2 = ax1.twinx()
ax2.plot(
    range(len(version_df)),
    version_df["AVG_SCORE"],
    linewidth=2,
    color="tab:blue",
    label="Average Rating"
)
ax2.set_ylabel("Average Rating", fontsize=11)
ax2.set_ylim(0, 5.1)
ax2.tick_params(axis="y", labelcolor="tab:blue")

# Combine legends
l1, lb1 = ax1.get_legend_handles_labels()
l2, lb2 = ax2.get_legend_handles_labels()
ax1.legend(l1 + l2, lb1 + lb2, loc="upper left", frameon=False)

# Final touches
ax1.grid(axis="y", linestyle="--", alpha=0.4)
plt.title("Average Rating and Review Volume by App Version", fontsize=13, pad=10)
plt.tight_layout()
plt.show()

"""Average Score & Sentiment by App Version"""

# Average Score & Sentiment by App Version

if "APP_VERSION" in df.columns and "SENTIMENT" in df.columns:
    version_sent = (
        df.groupby("APP_VERSION")
          .agg(
              MEAN_SCORE=("SCORE", "mean"),
              MEAN_SENT=("SENTIMENT", "mean"),
              COUNT=("REVIEW_ID", "count")
          )
          .reset_index()
          .dropna(subset=["APP_VERSION"])
    )

    # Filter versions with at least 50 reviews
    version_sent = version_sent[version_sent["COUNT"] >= 50]

    # Natural version sorting
    def version_key(v):
        parts = re.findall(r'\d+', str(v))
        return tuple(map(int, parts)) if parts else (0,)
    version_sent = version_sent.sort_values(
        "APP_VERSION", key=lambda s: s.map(version_key)
    ).reset_index(drop=True)

    # Plot
    fig, ax1 = plt.subplots(figsize=(14, 5))

    # Review count bars
    ax1.bar(
        version_sent["APP_VERSION"].astype(str),
        version_sent["COUNT"],
        edgecolor="black",
        alpha=0.35,
        linewidth=0.6,
        color="#9ecae1",
        label="Review Count"
    )
    ax1.set_ylabel("Review Count", fontsize=12, color="gray")

    # X-axis tick spacing
    xticks = version_sent["APP_VERSION"].astype(str).values
    step = max(1, len(xticks) // 20)
    ax1.set_xticks(range(0, len(xticks), step))
    ax1.set_xticklabels(xticks[::step], rotation=45, ha="right", fontsize=9)

    # Line plot: Avg Score and Sentiment
    ax2 = ax1.twinx()
    ax2.plot(
        range(len(version_sent)), version_sent["MEAN_SCORE"],
        marker="o", markersize=3, linewidth=1.8, alpha=0.8,
        label="Avg Score", color="#1f77b4"
    )
    ax2.plot(
        range(len(version_sent)), version_sent["MEAN_SENT"],
        marker="s", markersize=3, linewidth=1.8, alpha=0.8,
        label="Avg Sentiment", color="#2ca02c"
    )
    ax2.set_ylim(0, 5)
    ax2.set_ylabel("Score / Sentiment", fontsize=12)

    # Grid and aesthetics
    ax1.grid(axis="y", linestyle="--", alpha=0.45)
    ax1.set_ylim(0, version_sent["COUNT"].max() * 1.15)
    plt.title("Average Score and Sentiment by App Version", fontsize=14, pad=12)
    ax1.legend(loc="upper left", frameon=False)
    ax2.legend(loc="upper right", frameon=False)
    plt.box(False)
    plt.tight_layout()
    plt.show()
else:
    print("Required columns not found: APP_VERSION and/or SENTIMENT")

"""8. Word & N-gram Analysis

Common Bigrams/Trigrams by Rating
"""

from sklearn.feature_extraction.text import CountVectorizer
import matplotlib.pyplot as plt

def top_ngrams(texts, ngram_range=(2, 3), top_k=25, min_df=10):
    """Return top frequent n-grams"""
    vec = CountVectorizer(stop_words="english", ngram_range=ngram_range, min_df=min_df)
    X = vec.fit_transform(texts)
    freqs = X.sum(axis=0).A1
    vocab = vec.get_feature_names_out()
    return pd.DataFrame({"ngram": vocab, "count": freqs}).sort_values("count", ascending=False).head(top_k)

# Get text lists by rating group
high_texts = df.loc[df["SCORE"] >= 4, "CONTENT"].dropna().astype(str).tolist()
low_texts  = df.loc[df["SCORE"] <= 2, "CONTENT"].dropna().astype(str).tolist()

# Print review counts
print(f"High-rating reviews: {len(high_texts)}")
print(f"Low-rating reviews:  {len(low_texts)}")

# Set min_df dynamically
min_df_high = 10 if len(high_texts) >= 200 else 2
min_df_low  = 10 if len(low_texts)  >= 200 else 2

# Extract top n-grams
top_high = top_ngrams(high_texts, min_df=min_df_high)
top_low  = top_ngrams(low_texts,  min_df=min_df_low)

# Plot high rating n-grams
plt.figure(figsize=(10, 6))
plt.barh(top_high["ngram"][::-1], top_high["count"][::-1], edgecolor="black")
plt.title("Common Bigrams/Trigrams — High Rating (SCORE ≥ 4)")
plt.tight_layout()
plt.show()

# Plot low rating n-grams
plt.figure(figsize=(10, 6))
plt.barh(top_low["ngram"][::-1], top_low["count"][::-1], edgecolor="black")
plt.title("Common Bigrams/Trigrams — Low Rating (SCORE ≤ 2)")
plt.tight_layout()
plt.show()

"""9. User Behavior

Rating Distribution by User Activity
"""

# Step 1: Mark active users if needed
if "USER_NAME" in df.columns and "IS_ACTIVE_USER" not in df.columns:
    user_counts = df["USER_NAME"].value_counts()
    active_users = user_counts[user_counts > 1]
    df["IS_ACTIVE_USER"] = df["USER_NAME"].isin(active_users.index)

# Step 2: Build score distribution table
counts = (
    df.pivot_table(
        index="IS_ACTIVE_USER",
        columns="SCORE",
        values="REVIEW_ID",
        aggfunc="count",
        fill_value=0
    ).sort_index(axis=1)
)

# Normalize to get share
shares = counts.div(counts.sum(axis=1), axis=0)
tmp = shares.stack().reset_index(name="SHARE")

# Step 3: Plot
custom_palette = {False: "#1f77b4", True: "#9467bd"}

plt.figure(figsize=(7, 4))
sns.barplot(
    x="SCORE", y="SHARE", hue="IS_ACTIVE_USER",
    data=tmp, palette=custom_palette, edgecolor="black"
)
plt.title("Score Share by User Activity", fontsize=13)
plt.ylabel("Share within Group")
plt.xlabel("Score")
plt.legend(title="Active User?", labels=["Normal", "Active"])
plt.tight_layout()
plt.show()

"""Sentiment, Rating, and Length Change Among Active Users

"""

if {"USER_NAME", "SENTIMENT", "SCORE", "CONTENT", "CREATED_AT"}.issubset(df.columns):

    # Identify active users (multiple reviews)
    active_users = df["USER_NAME"].value_counts()
    active_users = active_users[active_users > 1].index
    df_active = df[df["USER_NAME"].isin(active_users)].copy()

    # Review length
    df_active["REVIEW_LENGTH"] = df_active["CONTENT"].astype(str).apply(len)

    # Compute first/last values per user
    user_change = (
        df_active.sort_values(["USER_NAME", "CREATED_AT"])
        .groupby("USER_NAME")[["SENTIMENT", "SCORE", "REVIEW_LENGTH", "CREATED_AT"]]
        .agg(["first", "last"])
    )

    user_change.columns = [
        "sent_first", "sent_last",
        "score_first", "score_last",
        "len_first", "len_last",
        "date_first", "date_last"
    ]

    # Calculate deltas
    user_change["sent_delta"] = user_change["sent_last"] - user_change["sent_first"]
    user_change["score_delta"] = user_change["score_last"] - user_change["score_first"]
    user_change["len_delta"] = user_change["len_last"] - user_change["len_first"]
    user_change["days_gap"] = (user_change["date_last"] - user_change["date_first"]).dt.days

    # Summary of score direction
    up = (user_change["score_delta"] > 0).mean()
    down = (user_change["score_delta"] < 0).mean()
    same = (user_change["score_delta"] == 0).mean()

    print("Rating Change Summary (Active Users)")
    print(f"Increase: {up:.1%}")
    print(f"Decrease: {down:.1%}")
    print(f"No change: {same:.1%}")

    # Summary statistics
    print("\nSummary of Change among Active Users")
    print(user_change[["sent_delta", "score_delta", "len_delta", "days_gap"]].describe().round(3))

    print(f"\nMedian days between first and last review: {user_change['days_gap'].median():.0f}")
    print(f"Mean days between first and last review: {user_change['days_gap'].mean():.1f}")

    # Plot histograms
    fig, axes = plt.subplots(1, 4, figsize=(18, 4))

    sns.histplot(user_change["sent_delta"], bins=30, kde=True, color="skyblue", ax=axes[0])
    axes[0].axvline(0, color="red", linestyle="--")
    axes[0].set_title("Δ Sentiment (last - first)")

    sns.histplot(user_change["score_delta"], bins=30, kde=True, color="lightgreen", ax=axes[1])
    axes[1].axvline(0, color="red", linestyle="--")
    axes[1].set_title("Δ Score (last - first)")

    sns.histplot(user_change["len_delta"], bins=30, kde=True, color="orange", ax=axes[2])
    axes[2].axvline(0, color="red", linestyle="--")
    axes[2].set_title("Δ Review Length (last - first)")

    sns.histplot(user_change[user_change["days_gap"] < 365]["days_gap"],
                 bins=30, color="mediumpurple", ax=axes[3])
    axes[3].set_title("Days Between First & Last Reviews (<1 year)")
    axes[3].set_xlabel("Days Gap")
    axes[3].set_ylabel("User Count")

    for ax in axes:
        ax.grid(alpha=0.3)
        ax.set_xlabel("Change")

    plt.suptitle("Behavior Change Among Active Users", fontsize=14, y=1.05)
    plt.tight_layout()
    plt.show()

"""User Behavior Clustering"""

# User Behavior Clustering

user_features = df.groupby("USER_NAME").agg(
    REVIEW_COUNT=("REVIEW_ID", "count"),
    AVG_SCORE=("SCORE", "mean"),
    AVG_SENTIMENT=("SENTIMENT", "mean"),
    AVG_LENGTH=("WORD_COUNT", "mean")
).reset_index()

# Drop users with missing features
user_features = user_features.dropna(subset=["AVG_SCORE", "AVG_SENTIMENT", "AVG_LENGTH"])

# Remove extreme outliers (top 1% by review count)
user_features = user_features[
    user_features["REVIEW_COUNT"] <= user_features["REVIEW_COUNT"].quantile(0.99)
]

print(f"Total unique users: {len(user_features):,}")

# Select the correct feature columns using uppercase names
X = user_features[["REVIEW_COUNT", "AVG_SCORE", "AVG_SENTIMENT", "AVG_LENGTH"]]

# Normalize the features
X_scaled = StandardScaler().fit_transform(X)

# Fit KMeans
kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)
user_features["CLUSTER"] = kmeans.fit_predict(X_scaled)

# Cluster summary
cluster_summary = (
    user_features.groupby("CLUSTER")[["REVIEW_COUNT", "AVG_SCORE", "AVG_SENTIMENT", "AVG_LENGTH"]]
    .mean()
    .round(2)
)

print("Cluster summary:")
print(cluster_summary)

plt.figure(figsize=(7, 6))

sns.scatterplot(
    data=user_features.sample(min(3000, len(user_features)), random_state=1),
    x="AVG_SCORE", y="AVG_SENTIMENT", hue="CLUSTER", palette="Set2",
    alpha=0.7, edgecolor="black", linewidth=0.2
)

plt.title("User Behavior Clusters (Score vs Sentiment)", fontsize=13)
plt.xlabel("Average Rating (Score)")
plt.ylabel("Average Sentiment (Compound)")
plt.legend(title="Cluster", loc="best", frameon=False)
plt.tight_layout()
plt.show()

# Merge user cluster back to full df
version_cluster = (
    df.merge(user_features[["USER_NAME", "CLUSTER"]], on="USER_NAME", how="left")
      .groupby("APP_VERSION")["CLUSTER"]
      .value_counts()
      .unstack(fill_value=0)
)

# Sort versions numerically
def version_key(v):
    parts = re.findall(r'\d+', str(v))
    return tuple(map(int, parts)) if parts else (0,)

version_cluster = version_cluster.sort_index(key=lambda s: s.map(version_key))

# Plot stacked bar of cluster composition by app version
plt.figure(figsize=(12, 5))
(
    version_cluster
    .div(version_cluster.sum(axis=1), axis=0)  # convert to percentage per version
    .plot(
        kind="bar",
        stacked=True,
        colormap="Set2",
        figsize=(14, 6),
        width=0.8,
        edgecolor="black",
        linewidth=0.3
    )
)

plt.title("Cluster Composition by App Version", fontsize=14, pad=10)
plt.xlabel("App Version (chronological order)", fontsize=12)
plt.ylabel("Proportion of Users", fontsize=12)
plt.legend(title="Cluster", bbox_to_anchor=(1.02, 1), loc="upper left")

# X-axis ticks formatting
xticks = version_cluster.index.astype(str)
step = max(1, len(xticks) // 15)
plt.xticks(range(0, len(xticks), step), xticks[::step], rotation=45, ha="right")

plt.grid(axis="y", linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()